{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNLegG6UsvlczhHeaoCp/Ms",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yjin94606-art/-/blob/main/Untitled14.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j90DO0CCxnrR",
        "outputId": "8fd3e480-9554-4126-b343-4ca94fa2d640"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline, set_seed\n",
        "\n",
        "generator = pipeline('text-generation', model='gpt2')\n",
        "set_seed(42)\n",
        "\n",
        "print(\"simple example\")\n",
        "prompt = \"AI can\"\n",
        "results = generator(prompt, max_length = 50 , num_return_sequences=1)\n",
        "print(results[0]['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfnookNHxwQ1",
        "outputId": "23af8fbd-b195-4070-a41b-24c710a26483"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "simple example\n",
            "AI can be used to create a new database, or to create a custom database, or even to create a new database for a specific user. It can also be used to create several different databases at once.\n",
            "\n",
            "Some of the above examples show how to create a new database. If you have a database that you want to see, you can use the help screen to create a new database. If you have a database that you want to see, you can use the help screen to create a new database. If you have a database that you want to see, you can use the help screen to create a new database. If you have a database that you want to see, you can use the help screen to create a new database. If you have a database that you want to see, you can use the help screen to create a new database.\n",
            "\n",
            "How do I create a new database?\n",
            "\n",
            "You can create a new database by first creating a new entry in your database. The database you created can be used to create a new database. You can then use the help screen to create a new database.\n",
            "\n",
            "Note: If you have already created a new database, you can use the help screen to create a new database. To create a new database, you\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n 互动文本生成\")\n",
        "def interactive_advanced_generator():\n",
        "  while True:\n",
        "    prompt = input(\"\\n请输入一个文本开头（输入'quit'退出）\")\n",
        "    if prompt.lower() == 'quit':\n",
        "      break\n",
        "\n",
        "    length = input(\"请输入生成的最大长度（默认100）\")\n",
        "    length = int(length) if length.isdigit() else 100\n",
        "\n",
        "    num_samples = input(\"请输入生成样本数（1-3 默认为1）\")\n",
        "    num_samples = int(num_samples) if num_samples.isdigit() and 1 <= int(num_samples) <=3 else 1\n",
        "\n",
        "    print(\"\\n 生成中\")\n",
        "    results = generator(\n",
        "        prompt,\n",
        "        max_length = length,\n",
        "        num_return_sequences = num_samples,\n",
        "        temperature = 0.7,\n",
        "        do_sample = True\n",
        "    )\n",
        "\n",
        "    for i, result in enumerate(results):\n",
        "      print(f\"\\n样本 {i+1}:\")\n",
        "      print(result['generated_text'])\n",
        "\n",
        "interactive_advanced_generator()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tn6FMZktzjIj",
        "outputId": "6de02655-888f-437a-ea19-7b33057f9b40"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " 互动文本生成\n",
            "\n",
            "请输入一个文本开头（输入'quit'退出）My wife\n",
            "请输入生成的最大长度（默认100）200\n",
            "请输入生成样本数（1-3 默认为1）1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=200) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " 生成中\n",
            "\n",
            "样本 1:\n",
            "My wife and I are currently working on our first project which is a new book that will be published by the Toronto-based Simon & Schuster imprint. The book will focus on the struggles and struggles of women who are struggling with their sexual identity, in a way that will be relevant to that discussion in the future.\n",
            "\n",
            "We believe in our book and we are excited to share it with you.\n",
            "\n",
            "For those of you who have not read the book, I encourage you to scroll down the page – that's a long way from the book.\n",
            "\n",
            "The book is about the stories of those women, our struggles, and the ways that we have worked together to fight for equality, respect and dignity.\n",
            "\n",
            "And since we are women, we are dedicated to sharing our journey.\n",
            "\n",
            "We are proud to be a part of the movement that is creating change for women.\n",
            "\n",
            "And we are also proud to be a part of the movement that is creating a revolution for all.\n",
            "\n",
            "And we are proud to be a part of the movement that is creating a revolution for all.\n",
            "\n",
            "We are proud to be a part of the movement that is generating change for all.\n",
            "\n",
            "So, let's get started.\n",
            "\n",
            "That's it.\n",
            "\n",
            "\n",
            "\n",
            "请输入一个文本开头（输入'quit'退出）Tiler and his girl friend are playing \n",
            "请输入生成的最大长度（默认100）200\n",
            "请输入生成样本数（1-3 默认为1）1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=200) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " 生成中\n",
            "\n",
            "样本 1:\n",
            "Tiler and his girl friend are playing iphone 8, a new generation of iPhone users have been catching up on the latest generation of Apple's latest operating systems and apps. According to some, the latest iteration of Apple's popular operating system, iOS 9.3, is the best-looking. It doesn't look like the iPhone 7 or 7 Plus will be the same, but at least it's a bit better than the iPhone 5S or 5S Plus.\n",
            "\n",
            "The iPhone 7 and 7 Plus are one of the most popular iPhones in the world for now, and according to Apple, the iPhone 7 Plus is the best-looking iPhone ever.\n",
            "\n",
            "In fact, it's the most popular iPhone today in North America, and it's the fastest-growing version of the iPhone. The iPhone 7 Plus, on the other hand, is the most popular phone in North America for a while and is the most popular iPhone ever.\n",
            "\n",
            "A lot of people are saying that the iPhone 7 Plus will be the most beautiful iPhone in the world, and it has been since Apple released iOS 9.3. This is true, but not the case. You need an iPhone 7 Plus to see it.\n",
            "\n",
            "For those who don't want to listen to those who hate Apple's latest OS for a while\n"
          ]
        }
      ]
    }
  ]
}
